/**
 * Main Application - Controls app flow and state
 */

const App = {
    // Application State
    conversationHistory: [],
    currentImageBase64: null,
    isProcessing: false,
    
    /**
     * Initialize the application
     */
    init() {
        // Initialize UI
        UI.init();
        
        // Initialize speech module
        SpeechModule.initVoices();
        
        // Setup speech callbacks
        SpeechModule.onResult = (text) => this.handleUserSpeech(text);
        SpeechModule.onInterim = (text) => UI.updateStatus(`ðŸŽ¤ ë“£ëŠ” ì¤‘: "${text}"`);
        SpeechModule.onError = (error) => this.handleSpeechError(error);
        SpeechModule.onStateChange = (state) => this.handleSpeechStateChange(state);
        
        // Check API key
        if (!ApiKeyManager.exists()) {
            UI.showApiModal(true);
        } else {
            UI.showApiModal(false);
        }
        
        console.log('âœ… App initialized');
    },
    
    /**
     * Handle speech state changes
     * @param {string} state
     */
    handleSpeechStateChange(state) {
        switch(state) {
            case 'listening':
                UI.updateMicButton(true, SpeechModule.isMicEnabled);
                break;
            case 'stopped':
                UI.updateMicButton(false, SpeechModule.isMicEnabled);
                if (!this.isProcessing) {
                    UI.updateStatus('ðŸŽ¤ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”!');
                }
                break;
            case 'error':
                UI.updateMicButton(false, SpeechModule.isMicEnabled);
                break;
        }
    },
    
    /**
     * Handle speech recognition errors
     * @param {string} error
     */
    handleSpeechError(error) {
        switch(error) {
            case 'not-allowed':
                UI.showError('ë§ˆì´í¬ ê¶Œí•œì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ ì™¼ìª½ì˜ ðŸ”’ ì•„ì´ì½˜ì„ í´ë¦­í•˜ì—¬ ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”.');
                break;
            case 'no-speech':
                UI.updateStatus('ðŸŽ¤ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
                break;
            case 'audio-capture':
                UI.showError('ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.');
                break;
            case 'network':
                UI.showError('ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
                break;
            case 'aborted':
                // ì‚¬ìš©ìžê°€ ì¤‘ë‹¨í•œ ê²½ìš° - ë¬´ì‹œ
                break;
            default:
                if (error !== 'aborted') {
                    UI.updateStatus('âš ï¸ ì˜¤ë¥˜: ' + error + '. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
                }
        }
    },
    
    /**
     * Handle user speech input
     * @param {string} text
     */
    async handleUserSpeech(text) {
        if (!text.trim() || this.isProcessing) return;
        
        this.isProcessing = true;
        SpeechModule.stopListening();
        UI.updateMicButton(false);
        UI.updateStatus('â³ AIê°€ ìƒê° ì¤‘...');
        UI.hideError();
        
        // Add user message
        this.addMessage('user', text);
        
        try {
            // Get AI response
            const response = await GeminiAPI.generateResponse(
                text, 
                this.conversationHistory,
                this.currentImageBase64
            );
            
            // Add AI message
            this.addMessage('ai', response.aiResponse);
            UI.updateStatus('ðŸŽ¤ AIê°€ ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤...');
            
            // Speak the response
            await SpeechModule.speak(response.aiResponse);
            
            // Show suggestions
            UI.showSuggestions(response.suggestions, (text) => this.speakSuggestion(text));
            UI.updateStatus('ðŸŽ¤ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”!');
            
        } catch (error) {
            console.error('API Error:', error);
            UI.showError('API ì˜¤ë¥˜: ' + error.message);
            
            // Use fallback response
            const fallback = GeminiAPI.getFallbackResponse(text);
            this.addMessage('ai', fallback.aiResponse);
            await SpeechModule.speak(fallback.aiResponse);
            UI.showSuggestions(fallback.suggestions, (text) => this.speakSuggestion(text));
            UI.updateStatus('ðŸŽ¤ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”!');
        }
        
        this.isProcessing = false;
    },
    
    /**
     * Add message to conversation
     * @param {string} role - 'user' or 'ai'
     * @param {string} text
     */
    addMessage(role, text) {
        this.conversationHistory.push({ role, text });
        UI.updateConversation(this.conversationHistory);
    },
    
    /**
     * Speak a suggestion (without triggering AI response)
     * @param {string} text
     */
    async speakSuggestion(text) {
        UI.updateStatus('ðŸ”Š ë¬¸ìž¥ì„ ì½ì–´ë“œë¦½ë‹ˆë‹¤...');
        await SpeechModule.speak(text);
        UI.updateStatus('ðŸŽ¤ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”!');
    }
};

// ===================================
// Global Functions (called from HTML)
// ===================================

/**
 * Save API key and close modal
 */
function saveApiKey() {
    const key = UI.getApiKeyInput();
    if (key) {
        ApiKeyManager.set(key);
        UI.showApiModal(false);
    } else {
        alert('API í‚¤ë¥¼ ìž…ë ¥í•´ì£¼ì„¸ìš”.');
    }
}

/**
 * Start conversation
 */
async function startConversation() {
    // 1. ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
    UI.updateStatus('ðŸŽ¤ ë§ˆì´í¬ ê¶Œí•œì„ ìš”ì²­í•©ë‹ˆë‹¤...');
    const hasPermission = await SpeechModule.requestMicPermission();
    if (!hasPermission) {
        UI.showError('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”.');
        return;
    }
    
    // 2. ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
    if (!SpeechModule.initRecognition()) {
        UI.showError('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome ë¸Œë¼ìš°ì €ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
        return;
    }
    
    // 3. UI ì „í™˜
    UI.showMainScreen();
    UI.updateStatus('ðŸŽ¤ AIê°€ ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤...');
    
    // 4. í™˜ì˜ ë©”ì‹œì§€
    const welcomeMessage = "Hi there! It's so nice to meet you! I'm here to help you practice English. How's your day going so far?";
    
    App.addMessage('ai', welcomeMessage);
    await SpeechModule.speak(welcomeMessage);
    
    // 5. ì´ˆê¸° ì œì•ˆ
    const suggestions = [
        { text: "I'm good!", level: 'beginner', age: 5 },
        { text: "My day is going pretty well, thanks for asking.", level: 'intermediate', age: 10 },
        { text: "I'm having a wonderful day! I've been looking forward to practicing my English.", level: 'advanced', age: 20 }
    ];
    
    UI.showSuggestions(suggestions, (text) => App.speakSuggestion(text));
    UI.updateStatus('ðŸŽ¤ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”!');
    console.log('âœ… ëŒ€í™” ì‹œìž‘ ì™„ë£Œ. ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.');
}

/**
 * Toggle microphone
 */
function toggleMic() {
    console.log('ðŸŽ¤ toggleMic í˜¸ì¶œë¨, isListening:', SpeechModule.isListening, 'isSpeaking:', SpeechModule.isSpeaking, 'isProcessing:', App.isProcessing);
    
    if (App.isProcessing || SpeechModule.isSpeaking) {
        UI.updateStatus('â³ ìž ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...');
        return;
    }
    
    if (!SpeechModule.isMicEnabled) {
        UI.updateStatus('ðŸ”‡ ë§ˆì´í¬ê°€ êº¼ì ¸ìžˆìŠµë‹ˆë‹¤.');
        return;
    }
    
    if (SpeechModule.isListening) {
        SpeechModule.stopListening();
        UI.updateStatus('ðŸŽ¤ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”!');
    } else {
        SpeechModule.startListening();
    }
}

/**
 * Toggle microphone enabled state
 */
function toggleMicEnabled() {
    SpeechModule.isMicEnabled = !SpeechModule.isMicEnabled;
    SpeechModule.setMicEnabled(SpeechModule.isMicEnabled);
    UI.updateMicEnabledState(SpeechModule.isMicEnabled);
    UI.updateMicButton(SpeechModule.isListening, SpeechModule.isMicEnabled);
    
    UI.updateStatus(SpeechModule.isMicEnabled ? 'ðŸŽ¤ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”!' : 'ðŸ”‡ ë§ˆì´í¬ê°€ êº¼ì¡ŒìŠµë‹ˆë‹¤.');
}

/**
 * Handle image upload
 * @param {Event} event
 */
function handleImageUpload(event) {
    const file = event.target.files[0];
    if (!file) return;
    
    if (file.size > CONFIG.MAX_IMAGE_SIZE) {
        alert('ì´ë¯¸ì§€ í¬ê¸°ëŠ” 10MB ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.');
        return;
    }
    
    const reader = new FileReader();
    reader.onload = (e) => {
        const result = e.target.result;
        UI.showUploadedImage(result);
        App.currentImageBase64 = result.split(',')[1];
        UI.updateStatus('ðŸ–¼ï¸ ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ì— ëŒ€í•´ ë§í•´ë³´ì„¸ìš”!');
    };
    reader.readAsDataURL(file);
}

/**
 * Remove uploaded image
 * @param {Event} event
 */
function removeImage(event) {
    event.stopPropagation();
    App.currentImageBase64 = null;
    UI.clearUploadedImage();
}

/**
 * Share conversation
 */
function shareConversation() {
    const text = App.conversationHistory.map(m => 
        `${m.role === 'user' ? 'Me' : 'AI'}: ${m.text}`
    ).join('\n\n');
    
    if (navigator.share) {
        navigator.share({
            title: 'My English Practice',
            text: text
        });
    } else {
        navigator.clipboard.writeText(text).then(() => {
            alert('ëŒ€í™” ë‚´ìš©ì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!');
        });
    }
}

// ===================================
// Initialize on page load
// ===================================
window.onload = () => {
    App.init();
};
